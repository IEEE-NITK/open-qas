{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from fuzzywuzzy import fuzz, StringMatcher\n",
    "import csv\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "#Download this particular file from kaggle\n",
    "glove_data_file ='glove.6B.100d.txt'\n",
    "\n",
    "#Load pretrained word embeddings\n",
    "def loadGloveModel(gloveFile,words):   \n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        if(word in words):\n",
    "            embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "            model[word] = embedding\n",
    "    return model\n",
    "\n",
    "#Data cleaning and tokenising \n",
    "def cleaned_words(sentance):\n",
    "    words = re.split(r'\\W+', sentance)\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in words]\n",
    "    final_words=[]\n",
    "    for word in stripped:\n",
    "        if(word is not ''):\n",
    "            final_words.append(word)\n",
    "    return final_words\n",
    "\n",
    "\n",
    "#Calculating parts of speech of words in a text\n",
    "def pos_tagging_list(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent\n",
    "\n",
    "#Calculating name entity recognition of words in text\n",
    "def ner(doc):\n",
    "    tokenized_doc = nltk.word_tokenize(doc)\n",
    "    tagged_s = nltk.pos_tag(tokenized_doc)\n",
    "    chunked_s = nltk.ne_chunk(tagged_s)\n",
    "    named_entities={}\n",
    "    for tree in chunked_s:\n",
    "        if hasattr(tree,'label'):\n",
    "            entity_name = ' '.join(c[0] for c in tree.leaves())\n",
    "            entity_type = tree.label()\n",
    "            if entity_name not in named_entities.keys():\n",
    "                named_entities[entity_name]=entity_type\n",
    "    return named_entities\n",
    "\n",
    "#Finding lemmas of a word and checking if the word of para has a lemma in the question\n",
    "def get_word_synonyms_from_sent(word, sent):\n",
    "    word_synonyms = []\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemma_names():\n",
    "            if lemma in sent and lemma != word:\n",
    "                word_synonyms.append(lemma)\n",
    "    return word_synonyms\n",
    "\n",
    "#Calculating term frequency of a word (TF)\n",
    "def term_frequency(words):\n",
    "    word_counts = {}\n",
    "    for word in words:\n",
    "        if(word in word_counts.keys()):\n",
    "            word_counts[word]=word_counts[word]+1\n",
    "        else:\n",
    "            word_counts[word]=1\n",
    "    for key,value in word_counts.items():\n",
    "        word_counts[key]= value/len(words)\n",
    "    return word_counts\n",
    "\n",
    "#Checking if a word and question word are exact matches\n",
    "def exact_match(word,question):\n",
    "    ans = []\n",
    "    synonym = get_word_synonyms_from_sent(word,question) \n",
    "    if(word in question):\n",
    "        ans.append(1)\n",
    "    else:\n",
    "        ans.append(0)\n",
    "        \n",
    "    if(word.lower() in question):\n",
    "        ans.append(1)\n",
    "    else:\n",
    "        ans.append(0)\n",
    "        \n",
    "    if(len(synonym) >0 ):\n",
    "        ans.append(1)\n",
    "    else:\n",
    "        ans.append(0)\n",
    "    return ans\n",
    "\n",
    "#Calculating similarity between a word and glove words\n",
    "def similarity(word,model_words):\n",
    "    most_sim_count =0\n",
    "    most_sim_word = word\n",
    "    for test_words in model_words.keys():\n",
    "        if fuzz.ratio(word,test_words)>most_sim_count :\n",
    "             most_sim_word = test_words\n",
    "    return most_sim_word\n",
    "\n",
    "#main function which performs paragraph encoding\n",
    "def paragraph_encoding(paragraph,question):\n",
    "    para_vector=[]\n",
    "    tokens = cleaned_words(paragraph)\n",
    "    tokens_question = cleaned_words(question)\n",
    "    \n",
    "    model = loadGloveModel(glove_data_file,tokens)\n",
    "    pos_tags = pos_tagging_list(\" \".join(tokens))\n",
    "    named_entity = ner(\" \".join(tokens))\n",
    "    \n",
    "    word_freq = term_frequency(tokens)\n",
    "    word_count = 0\n",
    "    \n",
    "    for word in tokens:\n",
    "        #Adding word embeddings\n",
    "        if word in model.keys():\n",
    "            word_embedding = model[word].tolist()\n",
    "        else:\n",
    "            most_similar_word = similarity(word,model)\n",
    "            word_embedding = model[most_similar_word].tolist()\n",
    "            \n",
    "        exact_match_vector = exact_match(word,tokens_question)\n",
    "        #Adding matched words\n",
    "        for binary in exact_match_vector:\n",
    "            word_embedding.append(binary)\n",
    "            \n",
    "        #Add manual_feature\n",
    "        #Add pos tags\n",
    "        word_embedding.append(pos_tags[word_count][1])\n",
    "        \n",
    "        #Add term frequency\n",
    "        word_embedding.append(word_freq[word])\n",
    "        \n",
    "        #Add named entity recognition\n",
    "        if word in named_entity:\n",
    "            word_embedding.append(named_entity[word])\n",
    "        else:\n",
    "            word_embedding.append('O')\n",
    "        para_vector.append(word_embedding)\n",
    "    return para_vector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "para= \"hello Andrew, i am very happy\"\n",
    "q = \"what is glad\"\n",
    "df = pd.DataFrame(paragraph_encoding(para,q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266880</td>\n",
       "      <td>0.396320</td>\n",
       "      <td>0.61690</td>\n",
       "      <td>-0.774510</td>\n",
       "      <td>-0.10390</td>\n",
       "      <td>0.266970</td>\n",
       "      <td>0.278800</td>\n",
       "      <td>0.30992</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>-0.085256</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.38486</td>\n",
       "      <td>0.35842</td>\n",
       "      <td>-0.484640</td>\n",
       "      <td>0.30728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.266880</td>\n",
       "      <td>0.396320</td>\n",
       "      <td>0.61690</td>\n",
       "      <td>-0.774510</td>\n",
       "      <td>-0.10390</td>\n",
       "      <td>0.266970</td>\n",
       "      <td>0.278800</td>\n",
       "      <td>0.30992</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>-0.085256</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.38486</td>\n",
       "      <td>0.35842</td>\n",
       "      <td>-0.484640</td>\n",
       "      <td>0.30728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.046539</td>\n",
       "      <td>0.619660</td>\n",
       "      <td>0.56647</td>\n",
       "      <td>-0.465840</td>\n",
       "      <td>-1.18900</td>\n",
       "      <td>0.445990</td>\n",
       "      <td>0.066035</td>\n",
       "      <td>0.31910</td>\n",
       "      <td>0.146790</td>\n",
       "      <td>-0.221190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.21540</td>\n",
       "      <td>-0.37616</td>\n",
       "      <td>-0.032502</td>\n",
       "      <td>0.80620</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.140220</td>\n",
       "      <td>0.024659</td>\n",
       "      <td>0.15813</td>\n",
       "      <td>-0.000743</td>\n",
       "      <td>-1.27080</td>\n",
       "      <td>0.596350</td>\n",
       "      <td>0.030512</td>\n",
       "      <td>0.43477</td>\n",
       "      <td>0.288730</td>\n",
       "      <td>-0.332620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.12119</td>\n",
       "      <td>-0.64749</td>\n",
       "      <td>0.488660</td>\n",
       "      <td>0.15445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.841360</td>\n",
       "      <td>0.309850</td>\n",
       "      <td>0.05817</td>\n",
       "      <td>-0.128200</td>\n",
       "      <td>-0.57563</td>\n",
       "      <td>-0.090958</td>\n",
       "      <td>-0.141380</td>\n",
       "      <td>0.29380</td>\n",
       "      <td>-0.102800</td>\n",
       "      <td>-0.322260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.96967</td>\n",
       "      <td>-0.74566</td>\n",
       "      <td>-0.110640</td>\n",
       "      <td>0.46134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.090436</td>\n",
       "      <td>0.196360</td>\n",
       "      <td>0.29474</td>\n",
       "      <td>-0.477060</td>\n",
       "      <td>-0.80436</td>\n",
       "      <td>0.307800</td>\n",
       "      <td>-0.552050</td>\n",
       "      <td>0.58453</td>\n",
       "      <td>-0.170560</td>\n",
       "      <td>-0.848460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.34524</td>\n",
       "      <td>0.11514</td>\n",
       "      <td>-0.408120</td>\n",
       "      <td>0.20203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1        2         3        4         5         6    \\\n",
       "0  0.266880  0.396320  0.61690 -0.774510 -0.10390  0.266970  0.278800   \n",
       "1  0.266880  0.396320  0.61690 -0.774510 -0.10390  0.266970  0.278800   \n",
       "2 -0.046539  0.619660  0.56647 -0.465840 -1.18900  0.445990  0.066035   \n",
       "3 -0.140220  0.024659  0.15813 -0.000743 -1.27080  0.596350  0.030512   \n",
       "4 -0.841360  0.309850  0.05817 -0.128200 -0.57563 -0.090958 -0.141380   \n",
       "5 -0.090436  0.196360  0.29474 -0.477060 -0.80436  0.307800 -0.552050   \n",
       "\n",
       "       7         8         9     ...        96       97        98       99   \\\n",
       "0  0.30992  0.005469 -0.085256   ...   -0.38486  0.35842 -0.484640  0.30728   \n",
       "1  0.30992  0.005469 -0.085256   ...   -0.38486  0.35842 -0.484640  0.30728   \n",
       "2  0.31910  0.146790 -0.221190   ...   -0.21540 -0.37616 -0.032502  0.80620   \n",
       "3  0.43477  0.288730 -0.332620   ...   -0.12119 -0.64749  0.488660  0.15445   \n",
       "4  0.29380 -0.102800 -0.322260   ...   -0.96967 -0.74566 -0.110640  0.46134   \n",
       "5  0.58453 -0.170560 -0.848460   ...   -0.34524  0.11514 -0.408120  0.20203   \n",
       "\n",
       "   100  101  102  103       104     105  \n",
       "0    0    0    0   NN  0.166667       O  \n",
       "1    0    0    0   NN  0.166667  PERSON  \n",
       "2    0    0    0   NN  0.166667       O  \n",
       "3    0    0    0   NN  0.166667       O  \n",
       "4    0    0    0   NN  0.166667       O  \n",
       "5    0    0    1   NN  0.166667       O  \n",
       "\n",
       "[6 rows x 106 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>104</th>\n",
       "      <th>103_NN</th>\n",
       "      <th>105_O</th>\n",
       "      <th>105_PERSON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266880</td>\n",
       "      <td>0.396320</td>\n",
       "      <td>0.61690</td>\n",
       "      <td>-0.774510</td>\n",
       "      <td>-0.10390</td>\n",
       "      <td>0.266970</td>\n",
       "      <td>0.278800</td>\n",
       "      <td>0.30992</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>-0.085256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.35842</td>\n",
       "      <td>-0.484640</td>\n",
       "      <td>0.30728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.266880</td>\n",
       "      <td>0.396320</td>\n",
       "      <td>0.61690</td>\n",
       "      <td>-0.774510</td>\n",
       "      <td>-0.10390</td>\n",
       "      <td>0.266970</td>\n",
       "      <td>0.278800</td>\n",
       "      <td>0.30992</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>-0.085256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.35842</td>\n",
       "      <td>-0.484640</td>\n",
       "      <td>0.30728</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.046539</td>\n",
       "      <td>0.619660</td>\n",
       "      <td>0.56647</td>\n",
       "      <td>-0.465840</td>\n",
       "      <td>-1.18900</td>\n",
       "      <td>0.445990</td>\n",
       "      <td>0.066035</td>\n",
       "      <td>0.31910</td>\n",
       "      <td>0.146790</td>\n",
       "      <td>-0.221190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.37616</td>\n",
       "      <td>-0.032502</td>\n",
       "      <td>0.80620</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.140220</td>\n",
       "      <td>0.024659</td>\n",
       "      <td>0.15813</td>\n",
       "      <td>-0.000743</td>\n",
       "      <td>-1.27080</td>\n",
       "      <td>0.596350</td>\n",
       "      <td>0.030512</td>\n",
       "      <td>0.43477</td>\n",
       "      <td>0.288730</td>\n",
       "      <td>-0.332620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.64749</td>\n",
       "      <td>0.488660</td>\n",
       "      <td>0.15445</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.841360</td>\n",
       "      <td>0.309850</td>\n",
       "      <td>0.05817</td>\n",
       "      <td>-0.128200</td>\n",
       "      <td>-0.57563</td>\n",
       "      <td>-0.090958</td>\n",
       "      <td>-0.141380</td>\n",
       "      <td>0.29380</td>\n",
       "      <td>-0.102800</td>\n",
       "      <td>-0.322260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.74566</td>\n",
       "      <td>-0.110640</td>\n",
       "      <td>0.46134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.090436</td>\n",
       "      <td>0.196360</td>\n",
       "      <td>0.29474</td>\n",
       "      <td>-0.477060</td>\n",
       "      <td>-0.80436</td>\n",
       "      <td>0.307800</td>\n",
       "      <td>-0.552050</td>\n",
       "      <td>0.58453</td>\n",
       "      <td>-0.170560</td>\n",
       "      <td>-0.848460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11514</td>\n",
       "      <td>-0.408120</td>\n",
       "      <td>0.20203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1        2         3        4         5         6  \\\n",
       "0  0.266880  0.396320  0.61690 -0.774510 -0.10390  0.266970  0.278800   \n",
       "1  0.266880  0.396320  0.61690 -0.774510 -0.10390  0.266970  0.278800   \n",
       "2 -0.046539  0.619660  0.56647 -0.465840 -1.18900  0.445990  0.066035   \n",
       "3 -0.140220  0.024659  0.15813 -0.000743 -1.27080  0.596350  0.030512   \n",
       "4 -0.841360  0.309850  0.05817 -0.128200 -0.57563 -0.090958 -0.141380   \n",
       "5 -0.090436  0.196360  0.29474 -0.477060 -0.80436  0.307800 -0.552050   \n",
       "\n",
       "         7         8         9     ...           97        98       99  100  \\\n",
       "0  0.30992  0.005469 -0.085256     ...      0.35842 -0.484640  0.30728    0   \n",
       "1  0.30992  0.005469 -0.085256     ...      0.35842 -0.484640  0.30728    0   \n",
       "2  0.31910  0.146790 -0.221190     ...     -0.37616 -0.032502  0.80620    0   \n",
       "3  0.43477  0.288730 -0.332620     ...     -0.64749  0.488660  0.15445    0   \n",
       "4  0.29380 -0.102800 -0.322260     ...     -0.74566 -0.110640  0.46134    0   \n",
       "5  0.58453 -0.170560 -0.848460     ...      0.11514 -0.408120  0.20203    0   \n",
       "\n",
       "   101  102       104  103_NN  105_O  105_PERSON  \n",
       "0    0    0  0.166667       1      1           0  \n",
       "1    0    0  0.166667       1      0           1  \n",
       "2    0    0  0.166667       1      1           0  \n",
       "3    0    0  0.166667       1      1           0  \n",
       "4    0    0  0.166667       1      1           0  \n",
       "5    0    1  0.166667       1      1           0  \n",
       "\n",
       "[6 rows x 107 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmodel():\n",
    "    input_layer\n",
    "    lstm_layer = LSTM(256, return_state=True)\n",
    "    model = Model(inputs=lstm_layer, outputs=lstm_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input tensors to a Model must come from `keras.layers.Input`. Received: <keras.layers.recurrent.LSTM object at 0x7feb812accc0> (missing previous layer metadata).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-690df4c67ecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-6fe6a3e24ed2>\u001b[0m in \u001b[0;36mcmodel\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlstm_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlstm_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlstm_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    163\u001b[0m                                  \u001b[0;34m'must come from `keras.layers.Input`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                                  \u001b[0;34m'Received: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                                  ' (missing previous layer metadata).')\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0;31m# Check that x is an input tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input tensors to a Model must come from `keras.layers.Input`. Received: <keras.layers.recurrent.LSTM object at 0x7feb812accc0> (missing previous layer metadata)."
     ]
    }
   ],
   "source": [
    "model = cmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
